{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob2\n",
    "import requests, json\n",
    "from lxml import html\n",
    "from astropy.time import Time\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "from astropy import constants as const\n",
    "import sys, getopt, argparse\n",
    "import re\n",
    "from time import sleep\n",
    "from astropy.io import fits\n",
    "from subprocess import call\n",
    "from lxml import html\n",
    "import webbrowser as wb\n",
    "from urllib.error import HTTPError\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global TOKEN, BASEURL\n",
    "GETTOKEN = '8e31426a-f04d-4a32-b470-54102e2d568d'      # Fritz API Key\n",
    "BASEURL = 'https://fritz.science/'                     # Fritz base url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"54916f1700966b3bd325fc1189763d86512bda1d\"     # TNS API Key\n",
    "\n",
    "# TNS URLs for real uploads\n",
    "TNS_BASE_URL = \"https://www.wis-tns.org/api/\"\n",
    "upload_url = \"https://www.wis-tns.org/api/file-upload\"\n",
    "report_url = \"https://www.wis-tns.org/api/bulk-report\"\n",
    "reply_url = \"https://www.wis-tns.org/api/bulk-report-reply\"\n",
    "\n",
    "# SANDBOX URLs for TNS upload trials\n",
    "SAND_TNS_BASE_URL = \"https://sandbox.wis-tns.org/api/\"\n",
    "SAND_upload_url = \"https://sandbox.wis-tns.org/api/file-upload\"\n",
    "SAND_report_url = \"https://sandbox.wis-tns.org/api/bulk-report\"\n",
    "SAND_reply_url = \"https://sandbox.wis-tns.org/api/bulk-report-reply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api(method, endpoint, data=None):\n",
    "    ''' Info : Basic API query, takes input the method (eg. GET, POST, etc.), the endpoint (i.e. API url) \n",
    "               and additional data for filtering\n",
    "        Returns : response in json format\n",
    "        CAUTION! : If the query doesn't go through, try putting the 'data' input in 'data' or 'params' \n",
    "                    argument in requests.request call\n",
    "    '''\n",
    "    headers = {'Authorization': f'token {GETTOKEN}'}\n",
    "    response = requests.request(method, endpoint, json=data, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n",
    "def get_source_api(ztfname):\n",
    "    ''' Info : Query a single source, takes input ZTF name\n",
    "        Returns : all basic data of that source (excludes photometry and spectra, \n",
    "                  includes redshift, classification, comments, etc.)\n",
    "    '''\n",
    "    url = BASEURL+'api/sources/'+ztfname+'?includeComments=true'\n",
    "    response = api('GET',url)\n",
    "    return response['data']    \n",
    "\n",
    "\n",
    "\n",
    "def get_group_ids(groupnames=['Redshift Completeness Factor', 'Census of the Local Universe Caltech']):\n",
    "    ''' Info : Query group ids of groups specified\n",
    "        Input : Name or names of groups in an array []\n",
    "        Returns : List of group  names and their group ids \n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/groups'\n",
    "    headers = {'Authorization': f'token {GETTOKEN}'}\n",
    "    groupnames = np.atleast_1d(groupnames)\n",
    "    grpids = []\n",
    "    for grpname in groupnames:\n",
    "        response = requests.request('GET',url,params={'name':grpname}, headers=headers).json()\n",
    "        answer = str(grpname)+' = '+str(response['data'][0]['id'])\n",
    "        grpids.append(answer)\n",
    "        \n",
    "    return grpids\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_sources(group_id, date):\n",
    "    ''' Info : Query number of sources saved in a group after a certain date\n",
    "        Input : group id, date [yyyy-mm-dd]\n",
    "        Returns : Number of sources saved after a given date to the specified group\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id+'&savedAfter='+date+'T00:00:00.000001'\n",
    "    response = api('GET',url)\n",
    "    return len(response['data']['sources'])\n",
    "\n",
    "\n",
    "\n",
    "def get_group_sources(group_id, date):\n",
    "    ''' Info : Query all sources saved in a group after a certain date\n",
    "        Input : group id, date [yyyy-mm-dd]\n",
    "        Returns : List of jsons of all sources in group(s)\n",
    "        Comment : Takes a little time based on the date\n",
    "    '''\n",
    "    \n",
    "    sources = []\n",
    "    \n",
    "    for i in range (get_number_of_sources(group_id, date)):\n",
    "    \n",
    "        url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id+'&savedAfter='+date+'T00:00:00.000001'\n",
    "        response = api('GET',url)\n",
    "        ztfname = response['data']['sources'][i]['obj_id']\n",
    "        sources.append(ztfname)\n",
    "        \n",
    "    return sources \n",
    "\n",
    "\n",
    "\n",
    "def get_total_number_of_sources(group_id):\n",
    "    ''' Info : Query total number of sources saved in a group\n",
    "        Input : group id\n",
    "        Returns : Total number of sources saved in a group\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id\n",
    "    response = api('GET',url)\n",
    "    return len(response['data']['sources'])\n",
    "\n",
    "\n",
    "def get_all_group_sources(group_id):\n",
    "    ''' Info : Query all sources saved in a group\n",
    "        Input : group id\n",
    "        Returns : List of jsons of all sources in group(s)\n",
    "        Comment : Takes a long time\n",
    "    '''\n",
    "    \n",
    "    sources = []\n",
    "    \n",
    "    for i in range (get_number_of_sources(group_id)):\n",
    "    \n",
    "        url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id\n",
    "        response = api('GET',url)\n",
    "        ztfname = response['data']['sources'][i]['obj_id']\n",
    "        sources.append(ztfname)\n",
    "        \n",
    "    return sources \n",
    "\n",
    "\n",
    "def get_IAUname(ztfname):\n",
    "    \n",
    "    ''' Info : Query the TNS name for any source\n",
    "        Input : ZTFname\n",
    "        Returns : ATname\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/alerts_aux/'+ztfname\n",
    "    response = api('GET',url)\n",
    "    return response[\"data\"][\"cross_matches\"][\"TNS\"]\n",
    "\n",
    "\n",
    "def get_classification(ztfname):\n",
    "                        \n",
    "    ''' Info : Query the classification and classification date for any source\n",
    "        Input : ZTFname\n",
    "        Returns : Classification and Classification date\n",
    "        Comment : You need to choose the classification if there are multiple classifications\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/sources/'+ztfname+'/classifications'\n",
    "    response = api('GET',url)\n",
    "    output = response['data']\n",
    "    \n",
    "    if (len(output)< 1):\n",
    "        classification = \"No Classification found\"\n",
    "        classification_date = \"None\"\n",
    "    \n",
    "    if (len(output)==1):\n",
    "        \n",
    "        classification = response['data'][0]['classification']\n",
    "        classification_date = response['data'][0]['created_at'].split('T')[0]\n",
    "        \n",
    "    if (len(output) > 1):\n",
    "        \n",
    "        classification = []\n",
    "        classification_date = []\n",
    "                    \n",
    "        for i in range (len(output)):\n",
    "            \n",
    "            classify = response['data'][i]['classification']  \n",
    "            classify_date = response['data'][i]['created_at']\n",
    "                    \n",
    "            classification.append(classify)\n",
    "            classification_date.append(classify_date)\n",
    "                    \n",
    "        for i in range (len(classification)):\n",
    "        \n",
    "            print ((i+1),\")\", \"Classification: \", classification[i],  \"\\t Classification date:\", classification_date[i].split('T')[0])\n",
    "\n",
    "        user_input = input(\"Choose classification: \")\n",
    "\n",
    "        classification = classification[int(user_input)-1]\n",
    "        classification_date = classification_date[int(user_input)-1].split('T')[0]        \n",
    "        \n",
    "    return classification, classification_date\n",
    "\n",
    "\n",
    "def get_redshift(ztfname):\n",
    "                    \n",
    "    ''' Info : Query the redshift for any source\n",
    "        Input : ZTFname\n",
    "        Returns : redshift\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/sources/'+ztfname\n",
    "    response = api('GET',url)\n",
    "    \n",
    "    redshift = response['data']['redshift']\n",
    "    \n",
    "    if (redshift == None):\n",
    "        redshift = \"No redshift found\"\n",
    "    \n",
    "    return redshift\n",
    "\n",
    "\n",
    "def get_TNS_information(ztfname):\n",
    "    \n",
    "    url = BASEURL+'api/sources/'+ztfname\n",
    "    response = api('GET',url)\n",
    "        \n",
    "    IAU = get_IAUname(ztfname)\n",
    "\n",
    "    if not IAU:\n",
    "        IAU = \"Not reported to TNS\"\n",
    "        \n",
    "    else:   \n",
    "        IAU = IAU[0]['name']\n",
    "              \n",
    "    clas = get_classification(ztfname)\n",
    "        \n",
    "    if clas[1] == 'None':\n",
    "        clas = \"Not classified yet\"\n",
    "        \n",
    "    else: \n",
    "        clas = ('Classification: '+str(clas[0])+','+' Classification date: '+str(clas[1]))\n",
    "           \n",
    "    redshift = get_redshift(ztfname)\n",
    "           \n",
    "    if redshift == None:\n",
    "        redshift = \"No redshift found\"\n",
    "        \n",
    "    else:\n",
    "        redshift = ('redshift:'+str(redshift))        \n",
    "        \n",
    "    return ztfname, IAU, clas, redshift\n",
    "\n",
    "   \n",
    "def convert_to_jd(date):\n",
    "\n",
    "    d = Time(date, format='fits')\n",
    "    dat = d.jd\n",
    "    return dat\n",
    "\n",
    "\n",
    "def get_spectrum_api(spectrum_id):\n",
    "    ''' Info : Query all spectra corresponding to a source, takes input ZTF name\n",
    "        Returns : list of spectrum jsons\n",
    "    '''\n",
    "    url = BASEURL+'api/spectrum/'+str(spectrum_id)\n",
    "    response = api('GET',url)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_all_spectra_len(ztfname):\n",
    "    \n",
    "    url = BASEURL+'api/sources/'+ztfname+'/spectra'\n",
    "    response = api('GET',url)\n",
    "    return len(response['data']['spectra'])\n",
    "\n",
    "\n",
    "def get_all_spectra_id(ztfname):\n",
    "    ''' Info : Query all spectra corresponding to a source, takes input ZTF name\n",
    "        Returns : list of spectrum jsons\n",
    "    '''\n",
    "\n",
    "    spec_id = []\n",
    "    \n",
    "    for i in range (get_all_spectra_len(ztfname)):\n",
    "    \n",
    "        url = BASEURL+'api/sources/'+ztfname+'/spectra'\n",
    "        response = api('GET',url)\n",
    "        \n",
    "        specid = response['data']['spectra'][i]['id']\n",
    "        spec_id.append(specid)\n",
    "        \n",
    "    return spec_id\n",
    "\n",
    "\n",
    "def get_required_spectrum_id(ztfname):\n",
    "    \n",
    "    flag = 0\n",
    "    \n",
    "    spec = (get_all_spectra_len(ztfname))\n",
    "    \n",
    "    name = []\n",
    "    date = []\n",
    "    \n",
    "    if spec == 0:\n",
    "        \n",
    "        specid = \"No Spectra Found\"\n",
    "        flag = 1\n",
    "        \n",
    "    if flag == 0:\n",
    "        \n",
    "        spec_id = get_all_spectra_id(ztfname)\n",
    "        \n",
    "        for s in range (spec):\n",
    "            \n",
    "            url = BASEURL+'api/sources/'+ztfname+'/spectra'\n",
    "            response = api('GET',url)\n",
    "\n",
    "            spec_name = response['data']['spectra'][s]['original_file_filename']\n",
    "            spec_date = response['data']['spectra'][s]['observed_at']\n",
    "            \n",
    "            name.append(spec_name)\n",
    "            date.append(spec_date.split('T')[0])\n",
    "\n",
    "        print (\"Please choose from the following spectra: \\n\")\n",
    "\n",
    "        for i in range (len(name)):\n",
    "            print ((i+1),\")\", \"spectrum name: \", name[i], \"spectrum date:\", date[i])\n",
    "            \n",
    "        wb.open(BASEURL+'source/'+ztfname, new=2) \n",
    "\n",
    "        user_input = input(\"Choose spectrum to upload: \")\n",
    "\n",
    "        specid = spec_id[int(user_input)-1]\n",
    "\n",
    "    return specid\n",
    "\n",
    "\n",
    "\n",
    "def write_ascii_file(ztfname):\n",
    "    \n",
    "    specid = get_required_spectrum_id(ztfname)\n",
    "    \n",
    "    flag = 0\n",
    "    \n",
    "    if (specid == 'No Spectra Found'):\n",
    "        spectrum_name = 'No Spectra Found'\n",
    "        print (spectrum_name)\n",
    "        flag = 1\n",
    "    \n",
    "    if flag == 0:\n",
    "        \n",
    "        a = get_spectrum_api(specid)\n",
    "\n",
    "        inst = (a['data']['instrument_name'])\n",
    "        #print (inst)\n",
    "    \n",
    "        if inst == 'SEDM':\n",
    "        \n",
    "            header = (a['data']['altdata'])\n",
    "            path = os.getcwd()\n",
    "\n",
    "            s = (ztfname+'_'+str(header['OBSDATE'])+'_'+str(inst)+'.ascii')\n",
    "\n",
    "            with open(path+'/data/'+s,'w') as f:\n",
    "                f.write(a['data']['original_file_string'])\n",
    "            f.close()\n",
    "\n",
    "            #print (s,'\\n')\n",
    "            spectrum_name = s\n",
    "        \n",
    "    \n",
    "        if inst == 'SPRAT':\n",
    "        \n",
    "        \n",
    "            header = (a['data']['altdata'])\n",
    "            \n",
    "            path = os.getcwd()\n",
    "\n",
    "            s = (ztfname+'_'+str(header['OBSDATE'].split('T')[0])+'_'+str(inst)+'.ascii')\n",
    "\n",
    "            with open(path+'/data/'+s,'w') as f:\n",
    "                f.write(a['data']['original_file_string'])\n",
    "            f.close()\n",
    "\n",
    "            #print (s,'\\n')\n",
    "            spectrum_name = s\n",
    "            \n",
    "            \n",
    "        if inst == 'ALFOSC':\n",
    "        \n",
    "            OBSDATE = a['data']['observed_at'].split('T')[0]\n",
    "            path = os.getcwd()\n",
    "\n",
    "            s = (ztfname+'_'+str(OBSDATE)+'_'+str(inst)+'.ascii')\n",
    "\n",
    "            with open(path+'/data/'+s,'w') as f:\n",
    "                f.write(a['data']['original_file_string'])\n",
    "            f.close()\n",
    "\n",
    "            #print (s,'\\n')\n",
    "            spectrum_name = s\n",
    "\n",
    "\n",
    "        if inst == 'DBSP':\n",
    "            \n",
    "            wav = (a['data']['wavelengths'])\n",
    "            flux = (a['data']['fluxes'])\n",
    "            err = (a['data']['errors'])\n",
    "            \n",
    "            OBSDATE = a['data']['observed_at'].split('T')[0]\n",
    "\n",
    "            path = os.getcwd()\n",
    "\n",
    "            s = (ztfname+'_'+str(OBSDATE)+'_'+str(inst)+'.ascii')\n",
    "            \n",
    "            if err == None:\n",
    "                \n",
    "                with open(path+'/data/'+s,'w') as f:\n",
    "                \n",
    "                    for i in range(len(wav)):\n",
    "                        f.write(str(wav[i])+'\\t'+str(flux[i])+'\\n')\n",
    "                f.close()\n",
    "\n",
    "                #print (s,'\\n')\n",
    "                spectrum_name = s\n",
    "                \n",
    "            else:\n",
    "\n",
    "                with open(path+'/data/'+s,'w') as f:\n",
    "\n",
    "                    for i in range(len(wav)):\n",
    "                        f.write(str(wav[i])+'\\t'+str(flux[i])+'\\t'+str(err[i])+'\\n')\n",
    "                f.close()\n",
    "\n",
    "                #print (s,'\\n')\n",
    "                spectrum_name = s\n",
    "            \n",
    "            \n",
    "        if inst == 'DIS':\n",
    "\n",
    "            #obsdate = a['data']['original_file_string'].split('#')[6]\n",
    "            #a,b = obsdate.split(' ', 1)\n",
    "            #c,OBSDATE = b.split(' ', 1)\n",
    "            #OBSDATE = OBSDATE.split('T')[0]\n",
    "            \n",
    "            obsdate = a['data']['observed_at']\n",
    "            OBSDATE = obsdate.split('T')[0]\n",
    "            \n",
    "            path = os.getcwd()\n",
    "            path = path+'/data/'\n",
    "\n",
    "            s = (ztfname+'_'+str(OBSDATE)+'_'+str(inst)+'.ascii')\n",
    "            \n",
    "            a = get_spectrum_api(specid)\n",
    "\n",
    "            with open(path+s,'w') as f:\n",
    "                f.write(a['data']['original_file_string'])\n",
    "            f.close()\n",
    "\n",
    "            #print (s,'\\n')\n",
    "            spectrum_name = s\n",
    "            \n",
    "            \n",
    "        if inst == 'KAST':\n",
    "\n",
    "            \n",
    "            obsdate = a['data']['observed_at']\n",
    "            OBSDATE = obsdate.split('T')[0]\n",
    "            \n",
    "            path = os.getcwd()\n",
    "            path = path+'/data/'\n",
    "\n",
    "            s = (ztfname+'_'+str(OBSDATE)+'_'+str(inst)+'.ascii')\n",
    "            \n",
    "            a = get_spectrum_api(specid)\n",
    "\n",
    "            with open(path+s,'w') as f:\n",
    "                f.write(a['data']['original_file_string'])\n",
    "            f.close()\n",
    "\n",
    "            #print (s,'\\n')\n",
    "            spectrum_name = s\n",
    "            \n",
    "            \n",
    "        if inst == 'LRIS':\n",
    "            \n",
    "            wav = (a['data']['wavelengths'])\n",
    "            flux = (a['data']['fluxes'])\n",
    "            err = (a['data']['errors'])\n",
    "            \n",
    "            OBSDATE = a['data']['observed_at'].split('T')[0]\n",
    "\n",
    "            path = os.getcwd()\n",
    "\n",
    "            s = (ztfname+'_'+str(OBSDATE)+'_'+str(inst)+'.ascii')\n",
    "            \n",
    "            if err == None:\n",
    "                \n",
    "                with open(path+'/data/'+s,'w') as f:\n",
    "                \n",
    "                    for i in range(len(wav)):\n",
    "                        f.write(str(wav[i])+'\\t'+str(flux[i])+'\\n')\n",
    "                f.close()\n",
    "\n",
    "                #print (s,'\\n')\n",
    "                spectrum_name = s\n",
    "                \n",
    "            else:\n",
    "\n",
    "                with open(path+'/data/'+s,'w') as f:\n",
    "\n",
    "                    for i in range(len(wav)):\n",
    "                        f.write(str(wav[i])+'\\t'+str(flux[i])+'\\t'+str(err[i])+'\\n')\n",
    "                f.close()\n",
    "\n",
    "                #print (s,'\\n')\n",
    "                spectrum_name = s\n",
    "            \n",
    "    return spectrum_name, specid\n",
    "\n",
    "\n",
    "\n",
    "def APO(specid):\n",
    "    \n",
    "    a = get_spectrum_api(specid)\n",
    "    inst = (a['data']['instrument_name'])\n",
    "    \n",
    "    obsdate = a['data']['original_file_string']['observed_at']\n",
    "    \n",
    "    OBSDATE = obsdate\n",
    "    \n",
    "    a = get_spectrum_api(specid)\n",
    "\n",
    "    exptime = a['data']['original_file_string'].split('#')[9]\n",
    "    a,b = exptime.split(' ', 1)\n",
    "    c,EXPTIME = b.split(' ', 1)\n",
    "    \n",
    "    a = get_spectrum_api(specid)\n",
    "\n",
    "    observers = (a['data']['original_file_string'].split('#')[10])\n",
    "    a,b = observers.split(' ', 1)\n",
    "    c,OBSERVERS = b.split(' ', 1)\n",
    "    \n",
    "    a = get_spectrum_api(specid)\n",
    "\n",
    "    reducers = a['data']['original_file_string'].split('#')[11]\n",
    "    a,b = reducers.split(' ', 1)\n",
    "    c,d = b.split(' ', 1)\n",
    "    REDUCERS,e = d.split('\\n', 1)\n",
    "    \n",
    "    return OBSDATE.split(' \\n')[0], EXPTIME.split(' \\n')[0], OBSERVERS.split(' \\n')[0], REDUCERS\n",
    "\n",
    "\n",
    "def pprint(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    slightly more convenient function instead of print(get_pprint)\n",
    "\n",
    "    params:\n",
    "        *args (arguments to pass to get_pprint)\n",
    "        **kwargs (keyword arguments to pass to get_pprint)\n",
    "    \"\"\"\n",
    "    print(get_pprint(*args, **kwargs))\n",
    "    \n",
    "\n",
    "def post_comment(ztfname, text):\n",
    "    \n",
    "    \n",
    "    data = {  \"obj_id\": ztfname,\n",
    "              \"text\": text,\n",
    "           }\n",
    "\n",
    "    url = BASEURL+'api/comment'\n",
    "    \n",
    "    response = api('POST', url, data=data)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def delete_spectrum(spectrum_id):\n",
    "    url = BASEURL+'api/spectrum/'+spectrum_id\n",
    "    \n",
    "    response = api('DELETE', url)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def retrieve_spectrum(spectrum_id):\n",
    "    url = BASEURL+'api/spectrum/'+spectrum_id\n",
    "    \n",
    "    response = api('GET', url)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classi(ztfname):\n",
    "                        \n",
    "    ''' Info : Query the classification and classification date for any source\n",
    "        Input : ZTFname\n",
    "        Returns : Classification and Classification date\n",
    "        Comment : You need to choose the classification if there are multiple classifications\n",
    "    '''\n",
    "    try:\n",
    "        \n",
    "        url = BASEURL+'api/sources/'+ztfname+'/classifications'\n",
    "        response = api('GET',url)\n",
    "        output = response['data']\n",
    "\n",
    "        if (len(output)< 1):\n",
    "            classification = \"Not Classified\"\n",
    "            classification_date = \"None\"\n",
    "\n",
    "        if (len(output) >= 1):\n",
    "\n",
    "            classification = response['data'][(len(output)-1)]['classification']  \n",
    "            classification_date = response['data'][(len(output)-1)]['created_at']\n",
    "            \n",
    "    except KeyError as e:\n",
    "        classification = \"Error\"\n",
    "        classification_date = \"Error\"\n",
    "        \n",
    "    return classification, classification_date\n",
    "\n",
    "def get_TNSname(ztfname):\n",
    "    \n",
    "    ''' Info : Query the TNS name for any source\n",
    "        Input : ZTFname\n",
    "        Returns : ATname\n",
    "    '''\n",
    "    try:\n",
    "        \n",
    "        url = BASEURL+'api/alerts_aux/'+ztfname\n",
    "        response = api('GET',url)\n",
    "        IAU = response['data']['cross_matches']['TNS']\n",
    " \n",
    "        \n",
    "        if not IAU:\n",
    "            IAU = \"Not reported to TNS\"\n",
    "\n",
    "        else:   \n",
    "            IAU = IAU[0]['name']\n",
    "\n",
    "    except KeyError as e:\n",
    "        IAU = \"Error\"\n",
    "        \n",
    "    return IAU\n",
    "\n",
    "\n",
    "def get_number(group_id, date):\n",
    "    ''' Info : Query number of sources saved in a group after a certain date\n",
    "        Input : group id, date [yyyy-mm-dd]\n",
    "        Returns : Number of sources saved after a given date to the specified group\n",
    "    '''\n",
    "    \n",
    "    url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id+'&savedAfter='+date+'T00:00:00.000001'\n",
    "    response = api('GET',url)\n",
    "    return len(response['data']['sources'])\n",
    "\n",
    "\n",
    "\n",
    "def get_sources(group_id, date):\n",
    "    ''' Info : Query all sources saved in a group after a certain date\n",
    "        Input : group id, date [yyyy-mm-dd]\n",
    "        Returns : List of jsons of all sources in group(s)\n",
    "        Comment : Takes a little time based on the date\n",
    "    '''\n",
    "    \n",
    "    sources = []\n",
    "    \n",
    "    for i in range (get_number(group_id, date)):\n",
    "    \n",
    "        url = BASEURL+'api/sources?saveSummary=true&group_ids='+group_id+'&savedAfter='+date+'T00:00:00.000001'\n",
    "        response = api('GET',url)\n",
    "        ztfname = response['data']['sources'][i]['obj_id']\n",
    "        sources.append(ztfname)\n",
    "        \n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sourceclassification(outfile):\n",
    "    \n",
    "    dat = '2020-11-06' #Specify the date from which you want to check the saved sources\n",
    "\n",
    "    path = 'https://fritz.science/api/sources?group_ids=41&saveSummary=true&savedAfter='+dat+'T00:00:00.000001'\n",
    " \n",
    "    response = api('GET',path)\n",
    "    \n",
    "    srcs = []\n",
    "    dates = []\n",
    "    classify = []\n",
    "    class_date = []\n",
    "    TNS = []\n",
    "    \n",
    "    listdir = os.getcwd()\n",
    "    f = open (listdir+'/'+outfile+'.ascii','w')\n",
    "    f.write('Source Name'+'\\t'+'TNS Name'+'\\t'+'Saved Date'+'\\t'+'Classification'+'\\t'+'Classification Date'+'\\n')\n",
    "    \n",
    "    for i in range (get_number('41', dat)):\n",
    "            \n",
    "        source_name = response['data']['sources'][i]['obj_id']\n",
    "        saved_date = response['data']['sources'][i]['saved_at']\n",
    "        classification = get_classi(source_name)[0]\n",
    "        date = get_classi(source_name)[1]\n",
    "        IAU = get_TNSname(source_name)\n",
    "            \n",
    "        print (i, source_name)\n",
    "\n",
    "        srcs.append(source_name)\n",
    "        TNS.append(IAU)\n",
    "        dates.append(saved_date.split('T')[0])\n",
    "        classify.append(classification)\n",
    "        class_date.append(date.split('T')[0])\n",
    "\n",
    "        \n",
    "    output = sorted(zip(class_date, srcs, TNS, dates, classify), reverse=True)\n",
    "\n",
    "\n",
    "    for i in range (get_number('41', dat)):\n",
    "\n",
    "        f.write(output[i][1]+'\\t'+output[i][2]+'\\t'+output[i][3]+'\\t'+output[i][4]+'\\t'+output[i][0]+'\\n')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ZTF18aahsuyl\n",
      "1 ZTF18aansqom\n",
      "2 ZTF18aaszvfn\n",
      "3 ZTF18aatezaj\n",
      "4 ZTF18aatjfoe\n",
      "5 ZTF18aavvnzu\n",
      "6 ZTF18acsremz\n",
      "7 ZTF19aawevgq\n",
      "8 ZTF20aaobxzx\n",
      "9 ZTF20abtcijp\n",
      "10 ZTF20abvdtgl\n",
      "11 ZTF20acselme\n",
      "12 ZTF21aapdpup\n",
      "13 ZTF21aappdnv\n",
      "14 ZTF21aaqhuhd\n",
      "15 ZTF21aaqmoof\n",
      "16 ZTF21aaqprjz\n",
      "17 ZTF21aaqugxm\n",
      "18 ZTF21aaqupdt\n",
      "19 ZTF21aaqvuyf\n",
      "20 ZTF21aaqxiaj\n",
      "21 ZTF21aaqyqux\n",
      "22 ZTF21aaqyqwk\n",
      "23 ZTF21aaqytjr\n",
      "24 ZTF21aaqzkhx\n",
      "25 ZTF21aaqzmdg\n",
      "26 ZTF21aaqzqaa\n",
      "27 ZTF21aaqzrat\n",
      "28 ZTF21aaqztcg\n",
      "29 ZTF21aaradzm\n",
      "30 ZTF21aaragyr\n",
      "31 ZTF21aarakan\n",
      "32 ZTF21aarasky\n",
      "33 ZTF21aarbjun\n",
      "34 ZTF21aarcldd\n",
      "35 ZTF21aarcobt\n",
      "36 ZTF21aardsgh\n",
      "37 ZTF21aardybv\n",
      "38 ZTF21aareexg\n",
      "39 ZTF21aarejnt\n",
      "40 ZTF21aarenhl\n",
      "41 ZTF21aargjdw\n",
      "42 ZTF21aarhikz\n",
      "43 ZTF21aarhnwn\n",
      "44 ZTF21aarhzdh\n",
      "45 ZTF21aaridax\n",
      "46 ZTF21aarigsr\n",
      "47 ZTF21aarjczf\n",
      "48 ZTF21aarkoym\n",
      "49 ZTF21aarmjai\n",
      "50 ZTF21aarmkuj\n",
      "51 ZTF21aarmuxl\n",
      "52 ZTF21aarnjyd\n",
      "53 ZTF21aarohyu\n",
      "54 ZTF21aarojxa\n",
      "55 ZTF21aarqkes\n",
      "56 ZTF21aarrplo\n",
      "57 ZTF21aarrrsx\n",
      "58 ZTF21aarrwdu\n",
      "59 ZTF21aarskup\n",
      "60 ZTF21aarstlf\n",
      "61 ZTF21aartehc\n",
      "62 ZTF21aartgiv\n",
      "63 ZTF21aarucpz\n",
      "64 ZTF21aarwlht\n",
      "65 ZTF21aarxsfm\n",
      "66 ZTF21aarybxo\n",
      "67 ZTF21aarycru\n",
      "68 ZTF21aarycyl\n",
      "69 ZTF21aarzgql\n",
      "70 ZTF21aasafkl\n",
      "71 ZTF21aasaxdk\n",
      "72 ZTF21aasaxfg\n",
      "73 ZTF21aasbjgq\n",
      "74 ZTF21aasbkrl\n",
      "75 ZTF21aasbntf\n",
      "76 ZTF21aasbqqw\n",
      "77 ZTF21aasbxng\n",
      "78 ZTF21aasctwo\n",
      "79 ZTF21aascwrr\n",
      "80 ZTF21aasdhhn\n",
      "81 ZTF21aasdhhy\n",
      "82 ZTF21aasfseg\n",
      "83 ZTF21aasgcve\n",
      "84 ZTF21aasgffc\n",
      "85 ZTF21aaskwgm\n",
      "86 ZTF21aaskyvp\n",
      "87 ZTF21aassamj\n",
      "88 ZTF21aassaom\n",
      "89 ZTF21aastazz\n",
      "90 ZTF21aastzsn\n",
      "91 ZTF21aasuazz\n",
      "92 ZTF21aasufxv\n",
      "93 ZTF21aaswtok\n",
      "94 ZTF21aaswvyc\n",
      "95 ZTF21aasxgne\n",
      "96 ZTF21aasyayn\n",
      "97 ZTF21aasyydo\n",
      "98 ZTF21aasyzkt\n",
      "99 ZTF21aaszrim\n",
      "100 ZTF21aatdzmt\n",
      "101 ZTF21aateglh\n",
      "102 ZTF21aatghue\n",
      "103 ZTF21aathrnx\n",
      "104 ZTF21aatiolj\n",
      "105 ZTF21aatisro\n",
      "106 ZTF21aatitlf\n",
      "107 ZTF21aatjavc\n",
      "108 ZTF21aatjypi\n",
      "109 ZTF21aatkdcw\n",
      "110 ZTF21aatklhw\n",
      "111 ZTF21aatlbsi\n",
      "112 ZTF21aatlesr\n",
      "113 ZTF21aatmfnz\n",
      "114 ZTF21aatnpnl\n",
      "115 ZTF21aatnxwt\n",
      "116 ZTF21aatpsky\n",
      "117 ZTF21aatsafx\n",
      "118 ZTF21aatscez\n",
      "119 ZTF21aatvcdl\n",
      "120 ZTF21aatvqcl\n",
      "121 ZTF21aatwkkg\n",
      "122 ZTF21aatwkkt\n",
      "123 ZTF21aatwlhj\n",
      "124 ZTF21aatyplr\n",
      "125 ZTF21aauaksp\n",
      "126 ZTF21aaualej\n",
      "127 ZTF21aauamtx\n",
      "128 ZTF21aauapli\n",
      "129 ZTF21aaublej\n",
      "130 ZTF21aaubuml\n",
      "131 ZTF21aaucuqu\n",
      "132 ZTF21aaucuyq\n",
      "133 ZTF21aaufthj\n",
      "134 ZTF21aaufvpg\n",
      "135 ZTF21aaufwyh\n",
      "136 ZTF21aaugbus\n",
      "137 ZTF21aaukcog\n",
      "138 ZTF21aaunadg\n",
      "139 ZTF21aaupkow\n",
      "140 ZTF21aaupsoq\n",
      "141 ZTF21aauuybx\n",
      "142 ZTF21aauvmck\n",
      "143 ZTF21aauzzny\n",
      "144 ZTF21aavacsc\n",
      "145 ZTF21aavadbu\n",
      "146 ZTF21aavasiz\n",
      "147 ZTF21aavbrwr\n",
      "148 ZTF21aavheiv\n",
      "149 ZTF21aavhlry\n",
      "150 ZTF21aavhmav\n",
      "151 ZTF21aavhnpk\n",
      "152 ZTF21aavhsdw\n",
      "153 ZTF21aavidfz\n",
      "154 ZTF21aavodst\n",
      "155 ZTF21aavodtn\n",
      "156 ZTF21aavoete\n",
      "157 ZTF21aavoqpl\n",
      "158 ZTF21aavotzn\n",
      "159 ZTF21aavozbk\n",
      "160 ZTF21aavqphe\n",
      "161 ZTF21aavqwhh\n",
      "162 ZTF21aavuprl\n",
      "163 ZTF21aavuprt\n",
      "164 ZTF21aavutkm\n",
      "165 ZTF21aavxcdr\n",
      "166 ZTF21aavxruq\n",
      "167 ZTF21aawckpe\n",
      "168 ZTF21aawgvpe\n",
      "169 ZTF21aawgvpj\n",
      "170 ZTF21aawgzda\n",
      "171 ZTF21aawihwx\n",
      "172 ZTF21aawlmzl\n",
      "173 ZTF21aawlvmx\n",
      "174 ZTF21aawlwoy\n",
      "175 ZTF21aawmdxw\n",
      "176 ZTF21aawmtug\n",
      "177 ZTF21aawogdl\n",
      "178 ZTF21aawqczk\n",
      "179 ZTF21aawqpuf\n",
      "180 ZTF21aawtewf\n",
      "181 ZTF21aawxqia\n",
      "182 ZTF21aawyyha\n",
      "183 ZTF21aawzkdr\n",
      "184 ZTF21aawzsew\n",
      "185 ZTF21aaxgwtb\n",
      "186 ZTF21aaxgyzv\n",
      "187 ZTF21aaxgzln\n",
      "188 ZTF21aaxhinu\n",
      "189 ZTF21aaxhzru\n",
      "190 ZTF21aaxjiii\n",
      "191 ZTF21aaxjjwf\n",
      "192 ZTF21aaxjvyl\n",
      "193 ZTF21aaxljzc\n",
      "194 ZTF21aaxsnvk\n"
     ]
    }
   ],
   "source": [
    "sourceclassification('updated_classifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TNS_classification_ID(classification):    \n",
    "\n",
    "    class_ids = {'Afterglow':23, 'AGN':29, 'CV':27, 'Galaxy':30, 'Gap':60, 'Gap I':61, 'Gap II':62, 'ILRT':25, 'Kilonova':70, 'LBV':24,'M dwarf':210, 'Nova':26, 'Novae':26, 'QSO':31, 'SLSN-I':18, 'Ic-SLSN':18, 'SLSN-II':19, 'SLSN-R':20, 'SN':1, 'I':2, 'Type I':2, 'I-faint':15, 'I-rapid':16, 'Ia':3, 'Ia-norm':3, 'Ia-91bg':103,'Ia-91T':104, 'Ia-CSM':106, 'Ia-pec':100, 'Ia-SC':102, 'Ia-02cx':105,\n",
    "                'Ib':4, 'Ib-norm':4, 'Ib-Ca-rich':8, 'Ib-pec':107, 'Ib/c':6, 'SN Ibn':9, 'Ibn':9, 'Ic':5, 'Ic-norm':5, 'Ic-BL':7, 'Ic-pec':108, 'II':10, 'Type II':10, 'II-norm':10,\n",
    "                'II-pec':110, 'IIb':14, 'IIL':12, 'IIn':13, 'IIn-pec':112, 'IIP':11, 'SN impostor':99, 'Std-spec':50, 'TDE':120,\n",
    "                'Varstar':28, 'WR':200, 'WR-WC':202, 'WR-WN':201, 'WR-WO':203, 'Other':0}\n",
    "    \n",
    "    #keys = np.array(class_ids.keys())\n",
    "    for keys in class_ids:\n",
    "        if (keys == classification):\n",
    "            classkey = class_ids[keys]\n",
    "            return classkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TNS_instrument_ID(classification):\n",
    "\n",
    "    inst_ids = {'DBSP':1, 'ALFOSC': 41, 'LRIS': 3, 'DIS': 70, 'SEDM': 149, 'SPRAT': 156, 'GMOS': 6, 'KAST': 10, 'LFC': 2, 'TSPEC': 109}\n",
    "\n",
    "    #keys = np.array(class_ids.keys())\n",
    "    for keys in inst_ids:\n",
    "        if (keys == inst):\n",
    "            instkey = inst_ids[keys]\n",
    "            return instkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNSClassificationReport:\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.fitsName = ''\n",
    "        self.asciiName = ''\n",
    "        self.classifierName = ''\n",
    "        self.classificationID = ''\n",
    "        self.redshift = ''\n",
    "        self.classificationComments = ''\n",
    "        self.obsDate = ''\n",
    "        self.instrumentID = ''\n",
    "        self.expTime = ''\n",
    "        self.observers = ''\n",
    "        self.reducers = ''\n",
    "        self.specTypeID = ''\n",
    "        self.spectrumComments = ''\n",
    "        self.groupID = ''\n",
    "        self.spec_proprietary_period_value = ''\n",
    "        self.spec_proprietary_period_units = ''\n",
    "\n",
    "    def classificationDict(self):\n",
    "        classificationDict =  {\n",
    "            'classification_report' : {\n",
    "                '0' : {\n",
    "                    'name' : self.name,\n",
    "                    'classifier' : self.classifierName,\n",
    "                    'objtypeid' : self.classificationID,\n",
    "                    'redshift': self.redshift,\n",
    "                    'groupid' : self.groupID,\n",
    "                    'remarks' : self.classificationComments,\n",
    "                    'spectra' : {\n",
    "                        'spectra-group' : {\n",
    "                            '0' : {\n",
    "                                'obsdate' : self.obsDate,\n",
    "                                'instrumentid' : self.instrumentID,\n",
    "                                'exptime' : self.expTime,\n",
    "                                'observer' : self.observers,\n",
    "                                'reducer' : self.reducers,\n",
    "                                'spectypeid' : self.specTypeID,\n",
    "                                'ascii_file' : self.asciiName,\n",
    "                                'fits_file' : self.fitsName,\n",
    "                                'remarks' : self.spectrumComments,\n",
    "                                'spec_proprietary_period' : {\n",
    "                                    'spec_proprietary_period_value' : self.spec_proprietary_period_value,\n",
    "                                    'spec_proprietary_period_units' : self.spec_proprietary_period_units\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return classificationDict\n",
    "\n",
    "    def classificationJson(self):\n",
    "        return json.dumps(self.classificationDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_TNS(filename, base_url = upload_url, api_key = API_KEY, filetype='ascii'):\n",
    "    \n",
    "    \"\"\"\n",
    "    uploads a file to TNS and returns the response json\n",
    "    \"\"\"\n",
    "    url = base_url\n",
    "    data = {'api_key' : api_key}\n",
    "\n",
    "    if filetype is 'ascii':\n",
    "        files = [('files[]', (filename, open(filename), 'text/plain'))]\n",
    "\n",
    "    elif filetype is 'fits':\n",
    "        files = [('files[0]', (filename, open(filename, 'rb'),\n",
    "                               'application/fits'))]\n",
    "\n",
    "    if filename:\n",
    "        response = requests.post(url, data=data, files=files)\n",
    "        try:\n",
    "            return response.json()\n",
    "        except:\n",
    "            print(url, data, files, response.content, sep='\\n')\n",
    "            return False\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tns_classify(classificationReport, base_url= report_url, api_key=API_KEY):\n",
    "    \"\"\"\n",
    "    submits classification report to TNS and returns the response json\n",
    "    \"\"\"\n",
    "    url = base_url\n",
    "    data = {'api_key' : api_key, 'data' : classificationReport.classificationJson()}\n",
    "    response = requests.post(url, data=data).json()\n",
    "    if not response:\n",
    "        return False\n",
    "\n",
    "    res_code = response['id_code']\n",
    "    report_id = response['data']['report_id']\n",
    "    print(\"ID:\", report_id)\n",
    "    print(res_code, response['id_message'], \"reporting finished\")\n",
    "    if res_code == 200:\n",
    "        return report_id\n",
    "    else:\n",
    "        print(\"Result reporting didn't work\")\n",
    "        pprint(response)\n",
    "        print(\"re-submit classification, but don't re-upload files\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tns_feedback(report_id):\n",
    "    data = {'api_key': API_KEY, 'report_id': report_id}\n",
    "    \n",
    "    response = requests.post(reply_url, data=data).json()\n",
    "    \n",
    "    feedback_code = response['id_code']\n",
    "    print(feedback_code, response['id_message'], \"feedback finished\")\n",
    "    if feedback_code == 200:\n",
    "        return True\n",
    "    elif feedback_code == 404:\n",
    "        print(\"Waiting and retrying...\")\n",
    "        sleep(2)\n",
    "        try:\n",
    "            return tns_feedback(report_id)\n",
    "        except KeyboardInterrupt:\n",
    "            return False\n",
    "    elif feedback_code == 400:\n",
    "        print(response)\n",
    "        return False\n",
    "    else:\n",
    "        # error receiving the feedback from TNS about the upload\n",
    "        print(\"Something went wrong with the feedback, but the report may\",\n",
    "              \"still have been fine?\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloadfritzascii('RCF_sources') #download the updated list of sources saved to RCF in descending order\n",
    "\n",
    "#f = ascii.read(\"RCF_sources_copy.ascii\") #ascii file containing the names of sources and their saved dates\n",
    "#sources = f['col1']\n",
    "\n",
    "sources = ['ZTF21aaxhzru', 'ZTF21aavuprl']\n",
    "           \n",
    "           \n",
    "           \n",
    "for source in sources:\n",
    "    \n",
    "    flag = 0\n",
    "    ztfname = source\n",
    "    \n",
    "    for i in range (len(get_source_api(source)['comments'])):\n",
    "        \n",
    "        comment = get_source_api(source)['comments'][i]['text']\n",
    "        \n",
    "        if comment == 'Uploaded to TNS':\n",
    "            flag = 1\n",
    "        \n",
    "    if flag == 0:\n",
    "        \n",
    "        info = get_TNS_information(ztfname)\n",
    "        \n",
    "        if info[2] == 'Not classified yet':         #Check if classified\n",
    "            flag =1\n",
    "            continue  \n",
    "\n",
    "\n",
    "        a,b = (info[2]).split(',', 1)               #This is just to get the classification date\n",
    "        c,d = b.split(':', 1)\n",
    "        e,class_date = d.split(' ', 1)\n",
    "\n",
    "\n",
    "        k,l = (info[2]).split(':', 1)               #This is just to get the classification\n",
    "        m,n = l.split(',', 1)\n",
    "        o,classify = m.split(' ', 1)\n",
    "\n",
    "        print (classify, class_date)\n",
    "\n",
    "\n",
    "        print (info, '\\n')\n",
    "        print (\"Do you want to proceed with the report?\")\n",
    "\n",
    "        user_input = input(\"y/n: \")\n",
    "\n",
    "        if user_input == 'y':\n",
    "\n",
    "            spectrum_info = write_ascii_file(ztfname) #returns \"spectrum_name\"\n",
    "\n",
    "            spectrum_name = spectrum_info[0]\n",
    "\n",
    "            if spectrum_name == 'No Spectra Found':\n",
    "                flag = 1\n",
    "                continue\n",
    "\n",
    "            if flag == 0:\n",
    "\n",
    "                path = os.getcwd()\n",
    "\n",
    "                specfile = (path+'/data/'+spectrum_name)\n",
    "\n",
    "                files = specfile\n",
    "\n",
    "                specid = spectrum_info[1]\n",
    "\n",
    "                a = get_spectrum_api(specid)\n",
    "\n",
    "                inst = (a['data']['instrument_name'])\n",
    "\n",
    "\n",
    "                if inst == 'SEDM':\n",
    "\n",
    "                    classifiers = 'A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    header = (a['data']['altdata'])\n",
    "                    obsdate = str((header['UTC']).split('T')[0])+' '+str((header['UTC']).split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = obsdate\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    classificationReport.expTime = (header['EXPTIME'])\n",
    "                    classificationReport.observers = 'SEDmRobot'\n",
    "                    classificationReport.reducers = (header['REDUCER'])\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        # ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        tns_feedback(report_id)\n",
    "\n",
    "\n",
    "                if inst == 'SPRAT':\n",
    "\n",
    "                    classifiers = 'D. A. Perley, K. Taggart (LJMU), A. Dahiwale, C. Fremling (Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    header = (a['data']['altdata'])\n",
    "                    obsdate = str(header['OBSDATE'].split('T')[0])+' '+str(header['OBSDATE'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:] \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = obsdate\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    classificationReport.expTime = (header['EXPTIME'])\n",
    "                    classificationReport.observers = 'LTRobot'\n",
    "                    classificationReport.reducers = 'D. Perley'\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        # ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        tns_feedback(report_id)\n",
    "\n",
    "\n",
    "\n",
    "                if inst == 'ALFOSC':\n",
    "\n",
    "                    classifiers = 'A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    header = (a['data']['altdata'])\n",
    "                    obsdate = str(a['data']['observed_at'].split('T')[0])+' '+str(a['data']['observed_at'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = obsdate\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    classificationReport.expTime = (header['EXPTIME'])\n",
    "                    classificationReport.observers = (str(a['data']['observers'][0]['first_name'])+' '+str(a['data']['observers'][0]['last_name']))\n",
    "                    classificationReport.reducers = (str(a['data']['reducers'][0]['first_name'])+' '+str(a['data']['reducers'][0]['last_name']))\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        # ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        tns_feedback(report_id)\n",
    "\n",
    "\n",
    "\n",
    "                if inst == 'DBSP':\n",
    "\n",
    "                    classifiers = 'A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    OBSDATE = str(a['data']['observed_at'].split('T')[0])+' '+str(a['data']['observed_at'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = OBSDATE\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    classificationReport.expTime = '450'\n",
    "                    classificationReport.observers = (str(a['data']['observers'][0]['first_name'])+' '+str(a['data']['observers'][0]['last_name']))\n",
    "                    classificationReport.reducers = (str(a['data']['reducers'][0]['first_name'])+' '+str(a['data']['reducers'][0]['last_name']))\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        # ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        tns_feedback(report_id)  \n",
    "\n",
    "\n",
    "                if inst == 'LRIS':\n",
    "\n",
    "                    classifiers = 'A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "\n",
    "                    header = (a['data']['altdata'])\n",
    "\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    OBSDATE = str(a['data']['observed_at'].split('T')[0])+' '+str(a['data']['observed_at'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = OBSDATE\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    #classificationReport.expTime = '300'\n",
    "                    classificationReport.observers = (str(a['data']['observers'][0]['first_name'])+' '+str(a['data']['observers'][0]['last_name']))\n",
    "                    classificationReport.reducers = (str(a['data']['reducers'][0]['first_name'])+' '+str(a['data']['reducers'][0]['last_name']))\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        # ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        tns_feedback(report_id)  \n",
    "\n",
    "\n",
    "                if inst == 'DIS':\n",
    "\n",
    "                    classifiers = 'Melissa L. Graham (UW), A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "                    #obsdate = APO(specid)[0]  \n",
    "                    #exptime = APO(specid)[1]\n",
    "                    #observers = APO(specid)[2]\n",
    "                    #reducers = APO(specid)[3]\n",
    "\n",
    "                    obsdate = str(a['data']['observed_at'].split('T')[0])+' '+str(a['data']['observed_at'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = obsdate\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    #classificationReport.expTime = exptime\n",
    "                    #classificationReport.observers = observers\n",
    "                    #classificationReport.reducers = reducers\n",
    "                    classificationReport.observers = (str(a['data']['observers'][0]['first_name'])+' '+str(a['data']['observers'][0]['last_name']))\n",
    "                    classificationReport.reducers = (str(a['data']['reducers'][0]['first_name'])+' '+str(a['data']['reducers'][0]['last_name']))\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        #ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        tns_feedback(report_id)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        \n",
    "                        \n",
    "                if inst == 'KAST':\n",
    "\n",
    "                    #classifiers = 'Thomas G. Brink, Kishore C. Patra, Thomas de Jaeger, WeiKang Zheng, Benjamin E. Stahl, Alexei V. Filippenko (UC Berkeley), A. Dahiwale, C. Fremling (Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    #classifiers = 'A. Dahiwale, C. Fremling(Caltech) on behalf of the Zwicky Transient Facility (ZTF)'### Change accordingly\n",
    "                    source_group = 48 ### Require source group id from drop down list, 0 is for None\n",
    "                    spectypes = np.array(['object','host','sky','arcs','synthetic'])\n",
    "                    #proprietary_period = int(input(\"Proprietary period in years:\", x)\n",
    "                    proprietary_period = '0'\n",
    "                    proprietary_units = \"years\"\n",
    "                    spec_comments =''\n",
    "                    classification_comments = ''\n",
    "                    spectype='object'\n",
    "                    spectype_id = ['object', 'host', 'sky', 'arcs', 'synthetic'].index(spectype) + 1\n",
    "\n",
    "\n",
    "                    obsdate = str(a['data']['observed_at'].split('T')[0])+' '+str(a['data']['observed_at'].split('T')[1])\n",
    "\n",
    "                    classificationReport = TNSClassificationReport()\n",
    "                    classificationReport.name = get_IAUname(ztfname)[0]['name'][3:]  \n",
    "                    classificationReport.fitsName = ''\n",
    "                    classificationReport.asciiName = spectrum_name\n",
    "                    classificationReport.classifierName = classifiers\n",
    "                    classificationReport.classificationID = get_TNS_classification_ID(classify)\n",
    "                    classificationReport.redshift = get_redshift(ztfname)\n",
    "                    classificationReport.classificationComments = classification_comments\n",
    "                    classificationReport.obsDate = obsdate\n",
    "                    classificationReport.instrumentID = get_TNS_instrument_ID(inst)\n",
    "                    #classificationReport.expTime = exptime\n",
    "                    classificationReport.observers = 'Mike Rich'\n",
    "                    classificationReport.reducers = 'Mike Rich'\n",
    "                    #classificationReport.observers = (str(a['data']['observers'][0]['first_name'])+' '+str(a['data']['observers'][0]['last_name']))\n",
    "                    #classificationReport.reducers = (str(a['data']['reducers'][0]['first_name'])+' '+str(a['data']['reducers'][0]['last_name']))\n",
    "                    classificationReport.specTypeID = spectype_id\n",
    "                    classificationReport.spectrumComments = spec_comments\n",
    "                    classificationReport.groupID = source_group\n",
    "                    classificationReport.spec_proprietary_period_value = proprietary_period\n",
    "                    classificationReport.spec_proprietary_period_units = proprietary_units\n",
    "                    print(classificationReport.classificationDict())\n",
    "\n",
    "                    #pprint(classificationReport.fill(), tab='  ')\n",
    "                    proceed = input(\"\\nProceed with classification and upload? ([y]/n) : \")\n",
    "                    if proceed == 'y' and not proceed.strip() == '':\n",
    "\n",
    "                        #ASCII FILE UPLOAD\n",
    "                        print (\"\\n\")\n",
    "                        response = upload_to_TNS(files)\n",
    "                        print (response)\n",
    "\n",
    "                        if not response:\n",
    "                            print(\"File upload didn't work\")\n",
    "                            print(response)\n",
    "                            #return False\n",
    "\n",
    "                        print(response['id_code'], response['id_message'],\n",
    "                              \"\\nSuccessfully uploaded ascii spectrum\")\n",
    "                        #classificationReport.asciiName = response['data'][-1]\n",
    "\n",
    "                        report_id = tns_classify(classificationReport)\n",
    "                        tns_feedback(report_id)\n",
    "                        post_comment(ztfname, 'Uploaded to TNS')\n",
    "                        \n",
    "                        #print('deleting files now')\n",
    "                        #call(['rm', all_info['asciifile']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
